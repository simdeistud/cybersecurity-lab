{
 "cells": [
  {
   "cell_type": "code",
   "id": "e1e25226-3267-4503-8b9b-345187a2a6c1",
   "metadata": {},
   "source": [
    "import gzip\n",
    "from io import BytesIO\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import shutil\n",
    "from datetime import date, timedelta\n",
    "\n",
    "from pandas import concat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c39dc26-0b84-4c9f-931e-480a47338219",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7122124e-1ed7-4f00-99e0-e8061f55e5cd",
   "metadata": {},
   "source": [
    "from preprocessing_utils import preprocess_NVD_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d3b91608-cf6d-450a-8446-7a30a54c621e",
   "metadata": {},
   "source": [
    "data_path = 'data'\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "180ddd39-557d-4249-ad39-fd06f106ba53",
   "metadata": {},
   "source": [
    "# EPSS data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd89066-8051-4b7b-a6c7-fd87a1c9974a",
   "metadata": {},
   "source": [
    "Download the EPSS data from https://www.first.org/epss/data_stats into `data` folder"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_url = \"https://epss.empiricalsecurity.com/epss_scores-\"\n",
    "date_current = str(date.today() - timedelta(days=1))\n",
    "epss_url = base_url + date_current + \".csv.gz\"\n",
    "epss_filename = \"epss_scores-latest.csv\"\n",
    "\n",
    "response = requests.get(epss_url)\n",
    "if response.status_code != 200:\n",
    "    print(\"Error:\", response.status_code)\n",
    "else:\n",
    "    with open(os.path.join(data_path, epss_filename), \"wb\") as f:\n",
    "        f.write(gzip.decompress(response.content))"
   ],
   "id": "7aa203f8b783e9bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7d837721-b351-427d-8fac-216790c63030",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "epss_current = pd.read_csv(os.path.join(data_path, epss_filename), header=1)\n",
    "epss_current  # a Python statement with a variable name at the end of a cell will display its contents below\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b1f75ed9-5eab-43a7-9f7e-77e19a40d5a7",
   "metadata": {},
   "source": [
    "# NVD data"
   ]
  },
  {
   "cell_type": "code",
   "id": "59f48abf-b55b-4376-a88c-2695f93281eb",
   "metadata": {},
   "source": [
    "base_url = \"https://services.nvd.nist.gov/rest/json/cves/2.0\"\n",
    "date_start_NVD = '2025-09-01T00:00:00.000Z'  # Do NOT change these dates\n",
    "date_end_NVD = '2025-10-01T00:00:00.000Z'  # Do NOT change these dates\n",
    "start_index = 0\n",
    "results_per_page = 1000\n",
    "total_results = 1\n",
    "\n",
    "candidate_cves = []\n",
    "while start_index < total_results:\n",
    "    params = {\n",
    "        \"pubStartDate\": date_start_NVD,\n",
    "        \"pubEndDate\": date_end_NVD,\n",
    "        \"resultsPerPage\": results_per_page,\n",
    "        \"startIndex\": start_index,\n",
    "        \"noRejected\": \"\"\n",
    "    }\n",
    "    response = requests.get(base_url, params=params, timeout=6)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error:\", response.status_code)\n",
    "        break\n",
    "    data = response.json()\n",
    "    total_results = data.get(\"totalResults\", 0)\n",
    "    candidate_cves.extend(data.get(\"vulnerabilities\", []))\n",
    "    start_index += results_per_page\n",
    "    print(start_index)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f9210c3-11ab-4edd-8e72-136ecee23c22",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# normalize and preprocess data\n",
    "candidate_cves_df = pd.json_normalize(candidate_cves, record_path=None, sep='.', max_level=None)\n",
    "candidate_cves_df = preprocess_NVD_data(candidate_cves_df)\n",
    "\n",
    "# remove vulnerabilities marked as \"reject\" or \"reserved\"\n",
    "candidate_cves_df = candidate_cves_df[\n",
    "    (candidate_cves_df['cve.vulnStatus'] != 'Reserved') & (candidate_cves_df['cve.vulnStatus'] != 'Reject')]\n",
    "\n",
    "# merge NVD and EPSS data\n",
    "candidate_cves_df = candidate_cves_df.merge(epss_current, left_on=\"cve.id\", right_on=\"cve\", how=\"left\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8a433287-3840-4f6c-88c7-61ea90844810",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa77d3c3-db8e-4c2a-9ebd-8efad0f7185a",
   "metadata": {},
   "source": [
    "- display some examples (e.g., the first two CVE records)"
   ]
  },
  {
   "cell_type": "code",
   "id": "00c2bcea-ef6a-4305-8f76-75c6abfe28ff",
   "metadata": {},
   "source": "candidate_cves_df.head(2).T",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "37ec5219-2d00-4665-90b0-1f5b681f7dfd",
   "metadata": {},
   "source": [
    "- show a bar plot with the daily volume of published CVEs"
   ]
  },
  {
   "cell_type": "code",
   "id": "a45357d5-2b0d-418e-a528-7cdd887a0341",
   "metadata": {},
   "source": [
    "published_counts = candidate_cves_df[\"cve.published\"].dt.date.value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(x=published_counts.index, y=published_counts.values, color=\"k\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Number of CVEs Published\")\n",
    "plt.title(\"CVE Publications per Day\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ba40f44e-373a-407f-ae1e-0abd1ac51baf",
   "metadata": {},
   "source": [
    "- print the description of the last ten published vulnerabilities"
   ]
  },
  {
   "cell_type": "code",
   "id": "b616d5e6-98e1-4fe4-82a8-44d58f2074a8",
   "metadata": {},
   "source": [
    "for idx, x in enumerate(candidate_cves_df.sort_values('cve.published', ascending=False)[:10].iterrows()):\n",
    "    print('-' * 100)\n",
    "    print(x[1]['cve.id'], x[1]['cve.published'])\n",
    "    print(x[1].description)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "593e3cfd-f222-4042-a9ef-4a1e4ac9c58f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <font color='blue'><b><i>TODO</i></b>: produce plots or tables to address the folowing points</font>\n",
    "- <b>be creative</b>!\n",
    "    - How many vulnerabilities are published on CISA KEV? \n",
    "    - What are the the 20 most frequent vendors? (vendor name can be extracted from the `vulnerable_cpes` field).\n",
    "    - What are the 20 most frequent CWEs?\n",
    "    - Anaything else you see fit!\n",
    "\n",
    "<font color='blue'>Use text cells to discuss the outcome after each point</font>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We keep track of some information to help us later on.",
   "id": "7aad17a09da02007"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dropped_columns = []",
   "id": "756082f623d42b59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- What is the percentage of CVEs which received a CVSS score?",
   "id": "7e844854a838a134"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"{(candidate_cves_df[\"cvss_baseScore\"].count() / len(candidate_cves_df)) * 100:.02f}%\")",
   "id": "1f7b7c40a0bb70ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Report descriptive statistics of CVSS the CVSS base score and/or show its distribution",
   "id": "240a9c8e29e5aa00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "candidate_cves_df.info()",
   "id": "1af90597b08fc45d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We see that feature 6, 7, 8, and 9 have a very small amount of non null values. Therefore, we drop those columns to reduce dimensionality. We also remove all CVEs withtout CVSS data.",
   "id": "9d6efb3b6a9a8d76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dropped_columns = [\"cve.cisaExploitAdd\", \"cve.cisaActionDue\", \"cve.cisaRequiredAction\", \"cve.cisaVulnerabilityName\"]\n",
    "candidate_cves_df = candidate_cves_df.drop(columns=dropped_columns).dropna()"
   ],
   "id": "1791ae66e24685b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here we print some statistics about CVSS base score and we show its distribution related to publication date.",
   "id": "d96cd3cc861b50dc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "candidate_cves_df[\"cvss_baseScore\"].describe()",
   "id": "517e2ce0fec80dcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "sns.displot(x=candidate_cves_df[\"cvss_baseScore\"], color=\"k\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"CVSS\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"September 2025\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "38234cc1bdff9133",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It would seem that a relatively high number of CVEs published in september 2025 have a very high CVSS.",
   "id": "73b6cb0cde58863a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(x=candidate_cves_df[\"cve.published\"], y=candidate_cves_df[\"cvss_baseScore\"], color=\"k\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"CVSS\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "63fa1d2b0b0afa72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- #### Report descriptive statistics of EPSS and/or show its distribution",
   "id": "9e27c5bc68c9d55c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here we print some statistics about EPSS base score and we show its distribution related to publication date.",
   "id": "b1e880f0822cd33d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "candidate_cves_df[\"epss\"].describe()",
   "id": "339619233fb97d3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(x=candidate_cves_df[\"cve.published\"], y=candidate_cves_df[\"epss\"], color=\"k\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"EPSS\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "bbedbf7bc2f05970",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It is evident that, except for a couple of outliers, on average the EPSS is extremely low.",
   "id": "5bcd7c62b7c85dec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- #### Produce a scatter plot showing CVSS vs EPSS\n",
   "id": "dbd4965755499cb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(x=candidate_cves_df[\"cvss_baseScore\"], y=candidate_cves_df[\"epss\"], color=\"k\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"CVSS\")\n",
    "plt.ylabel(\"EPSS\")\n",
    "plt.title(\"September 2025\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b502b3551915eed2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we can see, the CVSS and EPSS are not really related with each other, even though the only times the EPSS is high enough, it's in the presence of an equally high CVSS. We can further visualize this lack of correlation with a correlation matrix:",
   "id": "81a7296bc0dde4ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(candidate_cves_df[[\"cvss_baseScore\", \"epss\", \"percentile\"]].corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"September 2025\")\n",
    "plt.show()"
   ],
   "id": "d84ac6317e18ee14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- #### Extra analysis",
   "id": "a8f72d8391d53557"
  },
  {
   "cell_type": "markdown",
   "id": "ca396b81-126f-4d52-af72-aa38120bcae0",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "markdown",
   "id": "fe548397-5c5e-437b-a735-e86264804ade",
   "metadata": {},
   "source": [
    "### <font color='blue'><b><i>TODO</i></b>\n",
    "- Filter the CVEs with low EPSS (<1%)\n",
    "- Select candidate CVEs\n",
    "    - From the resulting subset, select 10 CVEs that you think will reach high EPSS by the end of the course.\n",
    "    - Clearly describe the criteria you used for selection (e.g., high CVSS, popular software, CWE, popular vendor, number of references, keyword in description, manual inspection, random sampling, security blogs).\n",
    "- Share the selected CVE ids with the instructor (by two weeks). Use the code cell below to produce the csv file to submit.\n",
    "- Track the EPSS of your CVEs over time\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As per specification, we start by filtering the CVEs with low EPSS (<1%), removing all features we will not need, and turning the remaining ones into categorical.",
   "id": "88ed8e687f272735"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "candidate_cves_df = candidate_cves_df[candidate_cves_df['percentile'] <= 0.01].drop(columns=[\"epss\", \"percentile\", \"cve\", \"cve.published\", \"cve.lastModified\", \"cvss_version\", \"cve.references\", \"num_references\", \"vulnerable_cpes\"])",
   "id": "248ac73e21bdd66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cols_to_cat = [\"cve.sourceIdentifier\", \"cve.vulnStatus\", \"cvss_vectorString\", \"cvss_baseSeverity\", \"cvss_attackVector\",\n",
    "               \"cvss_attackComplexity\", \"cvss_privilegesRequired\", \"cvss_userInteraction\", \"cvss_scope\",\n",
    "               \"cvss_confidentialityImpact\", \"cvss_integrityImpact\",\n",
    "               \"cvss_availabilityImpact\"]\n",
    "candidate_cves_df[cols_to_cat] = candidate_cves_df[cols_to_cat].astype('category')\n",
    "candidate_cves_df.info()\n",
    "# save the final dataframe\n",
    "candidate_cves_df.to_csv(os.path.join(data_path, \"candidate_cves_df.csv\"))"
   ],
   "id": "76de2d45a87eb960",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## NVD 2022-2025 database\n",
    "We start by downloading all the CVEs that have been published between 2022 and 2024. This is because EPSS data is only available from 2021, and since we want to analyze CVEs behavior from when they were published, we need CVEs from after 2021."
   ],
   "id": "e8a6ca7f0f6617d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_url = \"https://nvd.nist.gov/feeds/json/cve/2.0/nvdcve-2.0-\"\n",
    "ext = \".json.gz\"\n",
    "\n",
    "# is json file doesn't exist use json to store all_cves inside it\n",
    "if not os.path.exists(os.path.join(data_path, \"2024_cves.json\")):\n",
    "    csv_url = base_url + \"2024\" + ext\n",
    "    response = requests.get(csv_url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error:\", response.status_code)\n",
    "    with open(os.path.join(data_path, \"2024_cves.json\"), \"wt\") as f:\n",
    "        json.dump(json.loads(gzip.decompress(response.content)), f, indent=2)\n",
    "cves = json.load(open(os.path.join(data_path, \"2024_cves.json\"))).get(\"vulnerabilities\", [])\n",
    "\n",
    "base_url = \"https://services.nvd.nist.gov/rest/json/cves/2.0\"\n",
    "cve_date_start = date(2022, 1, 1)\n",
    "cve_date_end = date(2025, 6, 1)\n",
    "cve_window_start = cve_date_start\n",
    "cves = []\n",
    "\n",
    "while cve_window_start + timedelta(days=30) <= cve_date_end:\n",
    "    start_index = 0\n",
    "    results_per_page = 1000\n",
    "    total_results = 1\n",
    "    date_start_NVD = f'{cve_window_start}T00:00:00.001Z'\n",
    "    date_end_NVD = f'{cve_window_start + timedelta(days=30)}T00:00:00.000Z'\n",
    "    print(f\"Downloading CVEs between {date_start_NVD} and {date_end_NVD}...\")\n",
    "    while start_index < total_results:\n",
    "        params = {\n",
    "            \"pubStartDate\": date_start_NVD,\n",
    "            \"pubEndDate\": date_end_NVD,\n",
    "            \"resultsPerPage\": results_per_page,\n",
    "            \"startIndex\": start_index,\n",
    "            \"noRejected\": \"\"\n",
    "        }\n",
    "        response = requests.get(base_url, params=params, timeout=6)\n",
    "        if response.status_code != 200:\n",
    "            print(\"Error:\", response.status_code)\n",
    "            break\n",
    "        data = response.json()\n",
    "        total_results = data.get(\"totalResults\", 0)\n",
    "        cves.extend(data.get(\"vulnerabilities\", []))\n",
    "        start_index += results_per_page\n",
    "        print(start_index)\n",
    "        sleep(1)\n",
    "    sleep(5)\n",
    "    cve_window_start += timedelta(days=30)"
   ],
   "id": "7c8f345f3fd61aa6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# normalize and preprocess data\n",
    "cves_df = pd.json_normalize(cves, record_path=None, sep='.', max_level=None)\n",
    "cves_df = preprocess_NVD_data(cves_df)"
   ],
   "id": "4f232e435491c748",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# remove vulnerabilities marked as \"reject\" or \"reserved\"\n",
    "cves_df = cves_df[(cves_df['cve.vulnStatus'] != 'Reserved') & (cves_df['cve.vulnStatus'] != 'Reject')]"
   ],
   "id": "6909cc6838ce95b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cves_df.describe()",
   "id": "760f06326dd452f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cves_df.isnull().sum()",
   "id": "73e322816fb51e6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Some features have a high number of missing values, so we drop the columns directly. Due to the sheer amount of samples, we also remove all the rows that have a missing value. Since we will aggregate data from all the CVEs' histories, we also drop date-related columns.",
   "id": "1f0d91243c0b1c9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = cves_df.drop(columns=[\"cve.cisaExploitAdd\", \"cve.evaluatorComment\", \"cve.cisaActionDue\", \"cve.cisaRequiredAction\",\n",
    "                          \"cve.cisaVulnerabilityName\", \"cve.published\", \"cve.lastModified\"]).dropna()\n",
    "X.info()"
   ],
   "id": "50fa5ad6c057d331",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X.head(3).T",
   "id": "c3281afa94e49080",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Since all CVEs share the same CVSS version, we can remove that column from our dataset.",
   "id": "2a95069c0698d16d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X = X.drop(columns=\"cvss_version\")",
   "id": "1b84eb4fb5e69cf0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Even though the number of references and cpes could be very useful, since they refer to the status of the CVE at the moment of download and do not contain time series data, we cannot use them to asses how the CVE evolved during its first months after publication. For this reason, we drop those columns too from our dataset.",
   "id": "8cf8611df739fd04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X = X.drop(columns=[\"cve.references\", \"num_references\", \"vulnerable_cpes\"])\n",
   "id": "c2a8134ccdc4fc89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We now transform all remaining variables into categorial ones.",
   "id": "4b9ba22ea772b702"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cols_to_cat = [\"cve.sourceIdentifier\", \"cve.vulnStatus\", \"cvss_vectorString\", \"cvss_baseSeverity\", \"cvss_attackVector\",\n",
    "               \"cvss_attackComplexity\", \"cvss_privilegesRequired\", \"cvss_userInteraction\", \"cvss_scope\",\n",
    "               \"cvss_confidentialityImpact\", \"cvss_integrityImpact\",\n",
    "               \"cvss_availabilityImpact\"]\n",
    "X[cols_to_cat] = X[cols_to_cat].astype('category')"
   ],
   "id": "4bdca1992b618e2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X.to_csv(os.path.join(data_path, \"cves_df.csv\"))",
   "id": "4ebf342757003d68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature construction from historical EPSS data\n",
    "\n",
    "For each CVE, we download its complete EPSS history. We take all CVEs that started with a percentile value < 1% and we calculate the following metrics for their first 3 months after publication:\n",
    "- $\\frac{\\sum_{t=1}^{T}pct_{i,t}-pct_{i,0}}{T}, T = 90$\n",
    "- $\\text{max}_t(pct_{i,t}-pct_{i,0}), t\\in[1,...,90]$"
   ],
   "id": "c653746a5d7a8b3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "window = 90\n",
    "\n",
    "start_date = date(2022, 1, 1)\n",
    "end_date = date(2025, 6, 1) + timedelta(days=window)\n",
    "epss_path = os.path.join(data_path, \"epss_history\")\n",
    "os.makedirs(epss_path, exist_ok=True)\n",
    "while start_date <= end_date:\n",
    "    url = \"https://epss.empiricalsecurity.com/epss_scores-{:%Y-%m-%d}.csv.gz\".format(start_date)\n",
    "    filename = os.path.join(epss_path, f\"epss_scores-{start_date:%Y-%m-%d}.csv.gz\")\n",
    "\n",
    "    # Skip if already downloaded\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"Skipping {filename} (already exists)\")\n",
    "    else:\n",
    "        print(f\"Downloading {url}...\")\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Saved to {filename}\")\n",
    "        else:\n",
    "            print(f\"No file for {start_date:%Y-%m-%d} (HTTP {response.status_code})\")\n",
    "        sleep(1)\n",
    "    start_date += timedelta(days=1)\n",
    "\n",
    "print(\"Download complete.\")"
   ],
   "id": "5409e141838b911d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Loop through all .gz files\n",
    "for filename in os.listdir(epss_path):\n",
    "    gz_path = os.path.join(epss_path, filename)\n",
    "    csv_path = os.path.join(epss_path, filename[:-3])  # Remove .gz\n",
    "    if filename.endswith(\".csv.gz\") and not os.path.exists(csv_path):\n",
    "        print(f\"Unzipping {gz_path} -> {csv_path}\")\n",
    "        with gzip.open(gz_path, \"rb\") as f_in:\n",
    "            with open(csv_path, \"wb\") as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(\"All files unzipped successfully.\")"
   ],
   "id": "3520cb955c102d7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We create a dictionary containing as keys all the CVEs published between 2022 and 2024, and as values a list of their first 90 percentile values since first publication on EPSS.",
   "id": "2715265a3ad2bb71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "percentiles_history = {}\n",
    "r = 0\n",
    "p = 0\n",
    "# Loop through all CSV files\n",
    "for filename in sorted(os.listdir(epss_path)):\n",
    "    if filename.endswith(\".csv\") and filename.startswith(\"epss_scores-\"):\n",
    "        file_path = os.path.join(epss_path, filename)\n",
    "        # Read file and acquire CVEs\n",
    "        with open(file_path, newline='', encoding=\"utf-8\") as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            print(f\"Reading {filename}...\")\n",
    "            for row in reader:\n",
    "                if len(row) >= 3 and row[0].strip().startswith((\"CVE-2022\", \"CVE-2023\", \"CVE-2024\")):\n",
    "                    r += 1\n",
    "                    if row[0].strip() not in percentiles_history:\n",
    "                        percentiles_history[row[0].strip()] = []\n",
    "                    if float(row[2].strip()) < 0.01:\n",
    "                        p += 1\n",
    "                    percentiles_history[row[0].strip()].append(float(row[2].strip()))\n",
    "                    #print(f\"Found {row[0].strip()} in {filename} with percentile {row[2]}\")\n",
    "\n",
    "# We cap the percentiles at the first 90 days\n",
    "for cve in percentiles_history:\n",
    "    percentiles_history[cve] = percentiles_history[cve][0:90]"
   ],
   "id": "b0c9aa731dca640b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"N of entries: {r}\\n N of 1%: {p}\")",
   "id": "460d85e6ccbfe8d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_first_percentile(cveid):\n",
    "    if cveid in percentiles_history:\n",
    "        return percentiles_history[cveid][0]\n",
    "    return None"
   ],
   "id": "e440d6864e03ec86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X = X[X[\"cve.id\"].apply(lambda c: c in percentiles_history)]",
   "id": "4bf09ee91e91aadd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "$$\\text{mean\\_daily\\_gain} = \\frac{\\sum_{t=1}^{T}pct_{i,t}-pct_{i,0}}{T} = \\frac{(\\sum_{t=1}^{T}pct_{i,t})-(T-1)pct_{i,0}}{T},  T = 90$$",
   "id": "24d1257a95485b86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def mean_daily_gain(values):\n",
    "    return (sum(values[1:-1]) - (len(values)-1)*values[0]) / len(values)"
   ],
   "id": "73f72966dc50a1df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "$$\\text{total\\_gain}=\\text{max}_t(pct_{i,t}-pct_{i,0}), t\\in[1,...,90]$$",
   "id": "9839a9ccf2d64155"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def total_gain(values):\n",
    "    res = 0\n",
    "    for value in values[1:-1]:\n",
    "        res = max(res, value - values[0])\n",
    "    return res"
   ],
   "id": "f122373c3ca03e05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# merge NVD and derivative metrics\n",
    "X['initial_percentile'] = X[\"cve.id\"].apply(get_first_percentile)\n",
    "X['mean_daily_gain'] = X[\"cve.id\"].apply(lambda c: mean_daily_gain(percentiles_history[c]))\n",
    "X['total_gain'] = X[\"cve.id\"].apply(lambda c: total_gain(percentiles_history[c]))\n",
    "# save the final dataframe\n",
    "X.to_csv(os.path.join(data_path, \"cves_df.csv\"))"
   ],
   "id": "56ed155a22431960",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we can see from the following plots, CVEs tend to start with an EPSS score sitting in the 10%. It is also evident how the mean daily gain and total gain over the first 90 days after publishing sit close to zero, meaning the vast majority of CVEs do not increase their threat level.",
   "id": "38285176a5ba00c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.ylabel(\"contribution%\")\n",
    "plt.hist(X[\"initial_percentile\"], bins=\"auto\", density=True)\n",
    "plt.xlabel(\"EPSS percentile on 1st day\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.ylabel(\"contribution%\")\n",
    "plt.hist(X[\"mean_daily_gain\"], bins=50, density=True)\n",
    "plt.xlabel(\"Mean daily gain in first 90 days\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.ylabel(\"contribution%\")\n",
    "plt.hist(x=X[\"total_gain\"], bins=50, density=True)\n",
    "plt.xlabel(\"Max gain in the first 90 days\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "c6d2d091728554a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X[X[\"initial_percentile\"] < 0.01].info()",
   "id": "4a0e6a8e8328c8c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "There are only 80 CVEs from 2022 to the middle of 2025 that have started with an EPSS below the 1% percentile. We will try three different ML-based approaches to select our final candidates to submit.",
   "id": "58788429df153a21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "candidate_cves_df = candidate_cves_df.drop(columns=[\"cve\", \"cve.published\", \"cve.lastModified\", \"cvss_version\", \"cve.references\", \"num_references\", \"vulnerable_cpes\"])\n",
    "candidate_cves_df.info()\n",
    "candidate_cves_df.to_csv(os.path.join(data_path, \"candidate_cves_df.csv\"))"
   ],
   "id": "ae4e597a69e13f49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# START FROM HERE IF YOU ALREADY DOWNLOADED EVERYTHING",
   "id": "8d3dcddc66907ebb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import gzip\n",
    "from io import BytesIO\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import shutil\n",
    "from datetime import date, timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from pandas import concat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.feature_selection import chi2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "from preprocessing_utils import preprocess_NVD_data\n",
    "\n",
    "data_path = 'data'\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)"
   ],
   "id": "6506061e31ff7f66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = pd.read_csv(os.path.join(data_path, \"cves_df.csv\")).drop(columns=\"Unnamed: 0\")\n",
    "candidate_cves_df = pd.read_csv(os.path.join(data_path, \"candidate_cves_df.csv\")).drop(columns=\"Unnamed: 0\")"
   ],
   "id": "350740710377eeea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X.info()",
   "id": "ea4e9cf55559d6d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Novelty detection with OneClassSVM\n",
    "\n",
    "Since we have collected a huge amount of CVEs with pretty low scores and that haven't \"achieved\" anything in their first 90 days, we will train a OneClassSVM on all CVEs that satisfy the following criteria:\n",
    "\n",
    "   - percentile on first day <= 0.1\n",
    "   - mean daily gain in first 90 days <= 0.1\n",
    "   - max gain in first 90 days <= 0.1\n",
    "\n",
    "This training set will be considered the \"losers\", and we hope to find some CVEs among our candidates that are detected as outliars (novel) by the SVM."
   ],
   "id": "c0d33f1f38babc21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sklearn\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ],
   "id": "e20f5b9e3ad81a1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_svm = X[X[\"initial_percentile\"] < 0.1]\n",
    "X_train_svm = X_train_svm[X_train_svm[\"mean_daily_gain\"] < 0.1]\n",
    "X_train_svm = X_train_svm[X_train_svm[\"total_gain\"] < 0.1]\n",
    "X_train_svm = X_train_svm.drop(columns=[\"initial_percentile\", \"mean_daily_gain\", \"total_gain\", \"cve.id\", \"description\", \"cwe_list\"])\n",
    "X_train_svm.info()"
   ],
   "id": "b60a02ca841d4695",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_test_svm = X[X[\"initial_percentile\"] >= 0.1]\n",
    "X_test_svm = X_test_svm[X_test_svm[\"mean_daily_gain\"] >= 0.1]\n",
    "X_test_svm = X_test_svm[X_test_svm[\"total_gain\"] >= 0.1]\n",
    "X_test_svm = X_test_svm.drop(columns=[\"initial_percentile\", \"mean_daily_gain\", \"total_gain\", \"cve.id\", \"description\", \"cwe_list\"])\n",
    "X_test_svm.info()"
   ],
   "id": "831e1814405fd9cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "encoder = OneHotEncoder()\n",
    "print(\"Encoding categorial features...\")\n",
    "X_svm_encode = pd.concat([X.drop(columns=[\"initial_percentile\", \"mean_daily_gain\", \"total_gain\", \"cve.id\", \"description\", \"cwe_list\"]), candidate_cves_df.drop(columns=[\"cve.id\", \"description\", \"cwe_list\"])])\n",
    "encoder.fit(X_svm_encode)\n",
    "X_train_svm_encoded = encoder.transform(X_train_svm)\n",
    "X_test_svm_encoded = encoder.transform(X_test_svm)"
   ],
   "id": "3641bdb4bd7efff3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "estimator = OneClassSVM()\n",
    "print(\"Fitting model...\")\n",
    "estimator.fit(X_train_svm_encoded)"
   ],
   "id": "975625c5623d4ae7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Testing...\")\n",
    "y_svm_test = estimator.predict(X_test_svm_encoded)\n",
    "print(f\"Accuracy on testing data: {len(y_svm_test[y_svm_test == -1]) / len(X_test_svm)}%\")"
   ],
   "id": "f55f01a841f73c37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "candidate_cves_df_encoded = encoder.transform(candidate_cves_df.drop(columns=[\"cve.id\", \"description\", \"cwe_list\"]))\n",
    "print(\"Predicting...\")\n",
    "y_svm_predict = estimator.predict(candidate_cves_df_encoded)\n",
    "print(f\"Outliars in candidates: {100*len(y_svm_predict[y_svm_predict == -1])/len(y_svm_predict):.02f}%\")\n",
    "y_svm_predict = [\"Outlier\" if p == -1 else \"Inlier\" for p in y_svm_predict]\n",
    "print(y_svm_predict)"
   ],
   "id": "735f9cc218f53a68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1bis. Novelty detection on the filtered dataset\n",
    "\n",
    "We try to train another OneClasSVM, this time on the dataset filtered by percentile < 0.01. Since the size of the dataset is so small (80 samples), this is performed just as an extra step."
   ],
   "id": "1abdb44417525f99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sklearn\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ],
   "id": "9c600f1351af65b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_svm = X[X[\"initial_percentile\"] < 0.01]\n",
    "X_train_svm = X_train_svm.drop(\n",
    "    columns=[\"initial_percentile\", \"mean_daily_gain\", \"total_gain\", \"cve.id\", \"description\", \"cwe_list\"])\n",
    "X_train_svm.info()"
   ],
   "id": "c3bf606860830024",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_test_svm = X[X[\"initial_percentile\"] >= 0.01]\n",
    "X_test_svm = X_test_svm.drop(\n",
    "    columns=[\"initial_percentile\", \"mean_daily_gain\", \"total_gain\", \"cve.id\", \"description\", \"cwe_list\"])\n",
    "X_test_svm.info()"
   ],
   "id": "f23fd3f6ad29962a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "encoder = OneHotEncoder()\n",
    "print(\"Encoding categorial features...\")\n",
    "X_svm_encode = pd.concat(\n",
    "    [X.drop(columns=[\"initial_percentile\", \"mean_daily_gain\", \"total_gain\", \"cve.id\", \"description\", \"cwe_list\"]),\n",
    "     candidate_cves_df.drop(columns=[\"cve.id\", \"description\", \"cwe_list\"])])\n",
    "encoder.fit(X_svm_encode)\n",
    "X_train_svm_encoded = encoder.transform(X_train_svm)\n",
    "X_test_svm_encoded = encoder.transform(X_test_svm)"
   ],
   "id": "973f7149de1989a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "estimator = OneClassSVM()\n",
    "print(\"Fitting model...\")\n",
    "estimator.fit(X_train_svm_encoded)"
   ],
   "id": "1c2acec349dfcc6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Testing...\")\n",
    "y_svm_test = estimator.predict(X_test_svm_encoded)\n",
    "print(f\"Accuracy on testing data: {len(y_svm_test[y_svm_test == -1]) / len(X_test_svm)}%\")"
   ],
   "id": "574b8e4663e32f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "candidate_cves_df_encoded = encoder.transform(candidate_cves_df.drop(columns=[\"cve.id\", \"description\", \"cwe_list\"]))\n",
    "print(\"Predicting...\")\n",
    "y_svm_predict = estimator.predict(candidate_cves_df_encoded)\n",
    "print(f\"Outliars in candidates: {100 * len(y_svm_predict[y_svm_predict == -1]) / len(y_svm_predict):.02f}%\")\n",
    "y_svm_predict = [\"Outlier\" if p == -1 else \"Inlier\" for p in y_svm_predict]\n",
    "print(y_svm_predict)"
   ],
   "id": "ec543cc29b832cd4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Metrics prediction with multi output RandomForest\n",
    "\n",
    "We use RandomForestRegressor on the whole dataset and see what its best predictions are for our candidate CVEs"
   ],
   "id": "158c8583c19646c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, root_mean_squared_error, accuracy_score"
   ],
   "id": "4e77f84cba38f214",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "encoder = OneHotEncoder()\n",
    "print(\"Encoding categorial features...\")\n",
    "X_rr_features = X.drop(columns=[\"initial_percentile\", \"mean_daily_gain\", \"total_gain\", \"cve.id\", \"description\", \"cwe_list\"])\n",
    "X_rr_encode = pd.concat([X_rr_features, candidate_cves_df.drop(columns=[\"cve.id\", \"description\", \"cwe_list\"])])\n",
    "encoder.fit(X_rr_encode)\n",
    "X_rr_features_encoded = encoder.transform(X_rr_features)"
   ],
   "id": "93611a8d27b8238d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Generating train/test split...\")\n",
    "targets = [\"mean_daily_gain\", \"total_gain\"]\n",
    "y_rr_targets = X[targets]\n",
    "X_rr_train, X_rr_test, y_rr_train, y_rr_test = train_test_split(X_rr_features_encoded, y_rr_targets, test_size=0.33, random_state=42)"
   ],
   "id": "ea72131f9cdadee4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Fitting model...\")\n",
    "rr = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "estimator = MultiOutputRegressor(rr, n_jobs=-1)\n",
    "estimator.fit(X_rr_train, y_rr_train)"
   ],
   "id": "5e5989d04b22975e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Testing...\")\n",
    "y_rr_predict = estimator.predict(X_rr_test)\n",
    "print(\"R^2 per target:\", r2_score(y_rr_test, y_rr_predict, multioutput='raw_values'))\n",
    "print(\"MSE per target:\", mean_squared_error(y_rr_test, y_rr_predict, multioutput='raw_values'))\n",
    "print(\"RMSE per target:\", root_mean_squared_error(y_rr_test, y_rr_predict, multioutput='raw_values'))"
   ],
   "id": "54e813c8467d6fee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "candidate_cves_df_encoded = encoder.transform(candidate_cves_df.drop(columns=[\"cve.id\", \"description\", \"cwe_list\"]))\n",
    "print(\"Predicting...\")\n",
    "y_rr_predict = estimator.predict(candidate_cves_df_encoded)\n",
    "print(y_rr_predict)"
   ],
   "id": "a696484013195be8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.bis Metric prediction on the filtered dataset\n",
    "\n",
    "We try to train another RandomForestRegressor, this time on the dataset filtered by percentile < 0.01. Since the size of the dataset is so small (80 samples), this is performed just as an extra step."
   ],
   "id": "981b77e92c1a687e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, root_mean_squared_error, accuracy_score"
   ],
   "id": "1acaf2b06bf86005",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "encoder = OneHotEncoder()\n",
    "print(\"Encoding categorial features...\")\n",
    "X_rr_features = X[X[\"initial_percentile\"] < 0.01]\n",
    "X_rr_features = X.drop(\n",
    "    columns=[\"initial_percentile\", \"mean_daily_gain\", \"total_gain\", \"cve.id\", \"description\", \"cwe_list\"])\n",
    "X_rr_encode = pd.concat([X_rr_features, candidate_cves_df.drop(columns=[\"cve.id\", \"description\", \"cwe_list\"])])\n",
    "encoder.fit(X_rr_encode)\n",
    "X_rr_features_encoded = encoder.transform(X_rr_features)\n",
    "print(\"Generating train/test split...\")\n",
    "targets = [\"mean_daily_gain\", \"total_gain\"]\n",
    "y_rr_targets = X[targets]\n",
    "X_rr_train, X_rr_test, y_rr_train, y_rr_test = train_test_split(X_rr_features_encoded,\n",
    "                                                                y_rr_targets,\n",
    "                                                                test_size=0.33,\n",
    "                                                                random_state=42)"
   ],
   "id": "31f854d17baf2c12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Fitting model...\")\n",
    "rr = RandomForestRegressor(n_estimators=1000, random_state=42, n_jobs=-1)\n",
    "estimator = MultiOutputRegressor(rr)\n",
    "estimator.fit(X_rr_train, y_rr_train)"
   ],
   "id": "4d66e7b53b0f65df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Testing...\")\n",
    "y_rr_predict = estimator.predict(X_rr_test)\n",
    "print(\"R^2 per target:\", r2_score(y_rr_test, y_rr_predict, multioutput='raw_values'))\n",
    "print(\"MSE per target:\", mean_squared_error(y_rr_test, y_rr_predict, multioutput='raw_values'))\n",
    "print(\"RMSE per target:\", root_mean_squared_error(y_rr_test, y_rr_predict, multioutput='raw_values'))"
   ],
   "id": "dc568175dd401f77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "candidate_cves_df_encoded = encoder.transform(candidate_cves_df.drop(columns=[\"cve.id\", \"description\", \"cwe_list\"]))\n",
    "print(\"Predicting...\")\n",
    "y_rr_predict = estimator.predict(candidate_cves_df_encoded)\n",
    "print(y_rr_predict)"
   ],
   "id": "f282e1540111a9be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Final analysis",
   "id": "e24060171fa1589e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We now merge the predictions with the candidates:",
   "id": "a7a38b473d3ffaf6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "candidate_cves_df[\"Status\"] = y_svm_predict\n",
    "candidate_cves_df[\"predicted_mean_daily_gain\"] = y_rr_predict.T[0]\n",
    "candidate_cves_df[\"predicted_total_gain\"] = y_rr_predict.T[1]\n",
    "candidate_cves_df.T"
   ],
   "id": "b1e2384941c7218e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We only care about outliers, so we drop the others.",
   "id": "16b963d417521e52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "candidate_cves_df = candidate_cves_df[candidate_cves_df[\"Status\"] == \"Outlier\"].drop(columns=\"Status\")",
   "id": "f0404361cb13e621",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We now sort the remaining CVEs by their two target metrics:",
   "id": "54569f8c70b41e20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "candidate_cves_df = candidate_cves_df.sort_values(by=[\"predicted_mean_daily_gain\", \"predicted_total_gain\"], ascending=False)",
   "id": "f8422438775d8be2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "At a cursory glance, we can see that all of Apple's and JetBrains' CVEs have already been fixed prior to publication, thus we exclude them.",
   "id": "6556ef53f925fe09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "candidate_cves_df = candidate_cves_df[candidate_cves_df[\"cve.sourceIdentifier\"] != \"cve@jetbrains.com\"]\n",
    "candidate_cves_df = candidate_cves_df[candidate_cves_df[\"cve.sourceIdentifier\"] != \"product-security@apple.com\"]\n",
    "candidate_cves_df"
   ],
   "id": "83dae0d4ac02cfbf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "By manual inspection, we also exclude CVE-2025-7445 and CVE-2025-59934 since they have been fixed. This leaves us with the first remaining 10 CVEs, which we will select for the lab activity.",
   "id": "8d02fb5c37e5a52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "candidate_cves_df = candidate_cves_df[candidate_cves_df[\"cve.id\"] != \"CVE-2025-7445\"]\n",
    "candidate_cves_df = candidate_cves_df[candidate_cves_df[\"cve.id\"] != \"CVE-2025-59934\"]\n",
    "candidate_cves_df"
   ],
   "id": "454aa781cb4cc431",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "candidate_cves_df.to_csv(os.path.join(data_path, \"candidate_cves_ranked_df.csv\"))",
   "id": "fdf1d09327cb9f3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nickname = 'ora_et_LABora'\n",
    "\n",
    "selected = ['CVE-2025-9364',\n",
    "            'CVE-2025-50255',\n",
    "            'CVE-2025-54588',\n",
    "            'CVE-2025-57520',\n",
    "            'CVE-2025-20364',\n",
    "            'CVE-2025-10205',\n",
    "            'CVE-2025-36899',\n",
    "            'CVE-2025-26419',\n",
    "            'CVE-2025-26420',\n",
    "            'CVE-2025-26427',\n",
    "            ]\n",
    "\n",
    "candidate_cves_df = candidate_cves_df[candidate_cves_df[\"cve.id\"].isin(selected)]\n",
    "candidate_cves_df.to_csv(os.path.join(data_path, f'{nickname}.csv'))"
   ],
   "id": "c1ab61f2cae7312c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
